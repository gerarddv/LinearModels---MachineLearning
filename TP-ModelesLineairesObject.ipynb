{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center> TP2: Modèles linéaires<br>\n",
    "    Perceptron, Adaline, Regression Logistique et SVM</center></h1>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons nous intéresser à l'implémentation des modèles du perceptron ('p'), de l'Adline ('a') , de la regression logistique ('r') et des SVM ('s') dont les pseudo-codes puvent être résumés comme suit:\n",
    "\n",
    "input: Train, eta, m, MaxEp, modele\n",
    "\n",
    "init : w\n",
    "\n",
    "epoque=0\n",
    "\n",
    "while epoque<=MaxEp\n",
    "\n",
    "    err=0\n",
    "\n",
    "    for i in 1:m\n",
    "\n",
    "        choisir un exemple (x,y) de Train de façon aléatoire\n",
    "\n",
    "        h <- w*x\n",
    "\n",
    "        if((modele = 'a') or (modele = 'r'))\n",
    "\n",
    "            w <- w - eta*grad(L(w))\n",
    "\n",
    "        elif((modele = 'p') and (y*h <= 0))\n",
    "\n",
    "            w <- w - eta*grad(L(w))\n",
    "\n",
    "        elif((modele = 's') and (1-y*h >= 0))\n",
    "\n",
    "            w <- w - eta*grad(L(w))\n",
    "\n",
    "     epoque <- epoque+1\n",
    "\n",
    "output: w\n",
    "\n",
    "\n",
    "Pour une fonction de prédiction $h_\\mathbf{w}(\\mathbf{x})=w_0+\\langle \\mathbf{w},\\mathbf{x}\\rangle$; $\\mathcal{L}(\\mathbf{w})$ est la fonction de coût qui dans le cas de \n",
    "- Perceptron: $\\mathcal{L}(\\mathbf{w})=(-y*h_\\mathbf{w}(\\mathbf{x}))$,\n",
    "- Adaline: $\\mathcal{L}(\\mathbf{w})=(y-h_\\mathbf{w}(\\mathbf{x}))^2$,\n",
    "- Régression logistique: $\\mathcal{L}(\\mathbf{w})=\\log(1+e^{-yh_\\mathbf{w}(\\mathbf{x})})$,\n",
    "- SVM: $\\mathcal{L}(\\mathbf{w})=\\max(0,1-y*h_\\mathbf{w}(\\mathbf{x}))$\n",
    "\n",
    "$grad(\\mathcal{L}(\\mathbf{w}))$ est le gradient de la fonction $\\mathcal{L}(\\mathbf{w})$ dont on a vu les expressions pour ces modèles en TD.\n",
    "\n",
    "\n",
    "<font color='red'><b>Question 1:</b></font> Créer une liste de 4 éléments correspondant à l'exemple ET logique; chaque élément de la liste est une liste dont la dernière caractéristique est la classe de l'exemple et les premières caractéristiques leurs coordonnées."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "#ET est notre exemple\n",
    "#ici le -1 c'est le 0 si on avait raisonné en binaire\n",
    "ET=np.array([[0, 0, -1], [0, 1, -1], [1, 0, -1], [1, 1, 1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  0 -1]\n",
      " [ 0  1 -1]\n",
      " [ 1  0 -1]\n",
      " [ 1  1  1]]\n"
     ]
    }
   ],
   "source": [
    "print(ET)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'><b>Question 2:</b></font> Coder le programme du Perceptron (modele = 'p').\n",
    "\n",
    "Indication: Vous pouvez écrire une fonction qui calcule le produit scalaire entre un exemple $\\mathbf{x}=(x_1,\\ldots,x_d)$ et le vecteur poids $\\mathbf{w}=(w_0,w_1,\\ldots,w_d)$:\n",
    "$\\langle \\mathbf{w},\\mathbf{x} \\rangle=w_0+\\sum_{j=1}^d w_j x_j$; et une autre qui pour une matrice de données qui n'ont pas servi à apprendre le vecteur poids $\\mathbf{w}$ (i.e. la base Test), calcule le taux d'erreur sur cette base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''w=(3,) et x=(4,2) Le produit scalaire est possible car x est un vecteur ligne et w est un vecteur colonne.\n",
    "w[1:]done (2,) et x[:,1:]done (4,2) donc le nombre de ligne de colonne de x[:,1:] est le même que celui de w[1:]\n",
    "\n",
    "'''\n",
    "\n",
    "'''Pour calculer le taux d'erreur, on va diviser le nombre de fois où le produit scalaire est négatif par la taille du\n",
    " de l'exemple x.En gros on fait la moyenne des exemples mal classés par rapport a la vrai sortie de l'exemple\n",
    "'''\n",
    "class LinearModel:\n",
    "    def __init__(self, N, eta):\n",
    "    #N matrix size, eta learning rate\n",
    "        self.w = np.zeros(N)\n",
    "        self.eta = eta\n",
    "\n",
    "    def h(self, x):\n",
    "        # Je veux avoir tous w sauf la 1er case(w est un array numpy et non une liste)\n",
    "        # v2:w[0]+sum(Xj*Wj for (Xj,Wj) in zip(x,w[1:]))\n",
    "        return self.w[0] + np.dot(x, self.w[1:])\n",
    "\n",
    "    # def model(self, x):\n",
    "    #     return 1 if (self.produit_scalaire(x) >= 0) else 0\n",
    "\n",
    "    # def prediction(self, X):\n",
    "    #     pred = []\n",
    "    #     for x in X:\n",
    "    #         result = self.model(x)\n",
    "    #         pred.append(result)\n",
    "    #     return np.array(pred)\n",
    "\n",
    "    def taux_erreur(self, Train):\n",
    "        nb_neg = 0\n",
    "        x = Train[:, :-1]\n",
    "        y = Train[:, -1]\n",
    "        for X, Y in zip(x, y):\n",
    "            # si l'exemple est mal classé\n",
    "            if Y * self.h(X) <= 0:\n",
    "                nb_neg += 1\n",
    "        return nb_neg / x.shape[0]\n",
    "    \n",
    "    def TAUX_ERREUR(self, Test):\n",
    "        nb_mal_classes = 0\n",
    "        X_test=Test[:,:-1]\n",
    "        Y_test=Test[:,-1]\n",
    "        for x, y in zip(X_test, Y_test):\n",
    "                nb_mal_classes =((self.h(x)*y)<=0).sum()\n",
    "        return nb_mal_classes / len(X_test)\n",
    "\n",
    "\n",
    " \n",
    "class Perceptron(LinearModel):\n",
    "    def fit(self, Train, m, MaxEp):\n",
    "        w = np.zeros(Train.shape[1])\n",
    "        for epoque in range(MaxEp):\n",
    "            # pour chaque exemple dans Train\n",
    "            for ligne in range(m):\n",
    "                # y est la sortie associé à l'exemple x[ligne].Elle se trouve sur la dernière colonne de x qui est la classe de l'exemple\n",
    "                x = Train[ligne, :-1]\n",
    "                y = Train[ligne, -1]\n",
    "                if y * self.h(x) <= 0:\n",
    "                    self.w[0] = self.w[0] + self.eta * y\n",
    "                    self.w[1:] = self.w[1:] + self.eta * y * x\n",
    "        return self.w\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'><b>Question 3:</b></font> Appliquer le programme du perceptron sur la base du ET logique, calculer le taux d'erreur du modèle sur cette base.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.2  0.2  0.1]\n",
      "taux d'erreur pour perceptrion  0.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "'''\n",
    "\"Train=base de données d'entraînement qui contient des exemples pour apprendre un modèle.\n",
    "\n",
    "Epoque=nombre de cycles d'apprentissage effectués.\n",
    "\n",
    "MaxEp=nombre maximum d'itérations pour l'algorithme, ce qui signifie que l'apprentissage s'arrêtera si le nombre d'itérations atteint MaxEp.\n",
    "\n",
    "m=nombre d'exemples dans Train.\n",
    "'''\n",
    "\n",
    "# Definition du pas d'apprentissage\n",
    "eta=0.1\n",
    "# Nombre d'itérations (époques)\n",
    "MaxEp = 500\n",
    "\n",
    "perceptron = Perceptron(len(ET[0]), eta)\n",
    "print(perceptron.fit(ET,ET.shape[0],MaxEp))\n",
    "print(\"taux d'erreur pour perceptrion \", perceptron.taux_erreur(ET))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'><b>Question 4:</b></font> Coder les modèles Adaline ('a'), Régression Logistique ('r') et SVM ('s') et reporter leur erreur sur le problème jouet de ET logique.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.55555556  1.11111111  1.05555556]\n",
      "taux d'erreur pour perceptrion  0.0\n",
      "[-12.89999094   6.67033192  11.19043712]\n",
      "taux d'erreur pour perceptrion  0.0\n",
      "[-3.2  2.2  2.1]\n",
      "taux d'erreur pour perceptrion  0.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "w_a=np.zeros(ET.shape[1]) \n",
    "w_r=np.zeros(ET.shape[1]) \n",
    "w_s=np.zeros(ET.shape[1]) \n",
    "\n",
    "class Adaline(LinearModel):\n",
    "    def fit(self, Train, m, MaxEp):\n",
    "        for epoque in range(MaxEp):\n",
    "            for ligne in range(m):\n",
    "                y=Train[ligne,-1]\n",
    "                x=Train[ligne,:-1]\n",
    "                res = self.h(x)\n",
    "                self.w[0]=self.w[0]+self.eta*(y-res)\n",
    "                self.w[1:]=self.w[1:]+self.eta*(y-res)*x\n",
    "        return self.w\n",
    "    \n",
    "class LogisticRegression(LinearModel):\n",
    "    def fit(self, Train, m, MaxEp):\n",
    "        for epoque in range(MaxEp):\n",
    "            for ligne in range(m):\n",
    "                y=Train[ligne,-1]\n",
    "                x=Train[ligne,:-1]\n",
    "                L=(1-(1/(1+np.exp(-y*self.h(x)))))\n",
    "                self.w[0]=self.w[0]+self.eta*y*L\n",
    "                self.w[1:]=self.w[1:]+self.eta*L*x\n",
    "        return self.w\n",
    "        \n",
    "class SVM(LinearModel):\n",
    "    def fit(self, Train, m, MaxEp):\n",
    "        for epoque in range(MaxEp):\n",
    "            for ligne in range(m):\n",
    "                y=Train[ligne,-1]\n",
    "                x=Train[ligne,:-1]\n",
    "                if y*self.h(x)<=1:\n",
    "                    self.w[0]=self.w[0]+self.eta*y\n",
    "                    self.w[1:]=self.w[1:]+self.eta*y*x\n",
    "        return self.w\n",
    "\n",
    "\n",
    "\n",
    "adaline =Adaline(len(ET[0]), eta)\n",
    "print(adaline.fit(ET,ET.shape[0],MaxEp))\n",
    "print(\"taux d'erreur pour perceptrion \", adaline.taux_erreur(ET))\n",
    "        \n",
    "\n",
    "regression_logistique = LogisticRegression(len(ET[0]), eta)\n",
    "print(regression_logistique.fit(ET,ET.shape[0],MaxEp))\n",
    "print(\"taux d'erreur pour perceptrion \", regression_logistique.taux_erreur(ET))\n",
    "\n",
    "svm = SVM(len(ET[0]), eta)\n",
    "print(svm.fit(ET,ET.shape[0],MaxEp))\n",
    "print(\"taux d'erreur pour perceptrion \", svm.taux_erreur(ET))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'><b>Question 5:</b></font> Nous allons maintenant nous intéresser au comportement de ces modèles sur la base sonar de la collection UCI (http://archive.ics.uci.edu/ml/index.php). Cette base contient 208 exemples en dimension 60 séparés par `,` et la dernière élément correspond à la classe de l'exemple.\n",
    "\n",
    "    1. Télécharger la collection avec la fonction read_table de la librairie pandas (https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_table.html). Les options nécessaires sont `sep=','` et `header=None`  \n",
    "    2. Créer une liste de listes correspondant à la collection; pour cela initialiser la première liste et en parcourant chaque ligne de la matrice de données; créer une liste associée en remplaçant le dernier élément par `-1` ou `+1` et insérer la dans la première liste. \n",
    "    Indication: Utiliser la fonction `loc`. \n",
    "    3. Scinder la liste en deux listes `x_train` (75%) and `x_test` (25%) en la mélangeant aléatoirement au préalable. \n",
    "    Indication: Utiliser les fonctions `shuffle` de la librairie `random` et `train_test_split` de la librairie `sklearn.model_selection`  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import sklearn.model_selection as sk\n",
    "from random import shuffle\n",
    "from sklearn.model_selection  import train_test_split\n",
    "\n",
    "data = pd.read_table('http://archive.ics.uci.edu/ml/machine-learning-databases/undocumented/connectionist-bench/sonar/sonar.all-data', sep=',', header=None)\n",
    "\n",
    "#Initialisation de la liste principale\n",
    "collection = []\n",
    "#On parcourt les lignes du dataframe\n",
    "for i in range(data.shape[0]):\n",
    "    ligne_collection=data.iloc[i].tolist()\n",
    "    #data.iloc[:,-1] = data.iloc[:,-1].replace('R',1).replace('M',-1) ou data[60] = np.where(data[60]=='R', 1, -1)\n",
    "    if ligne_collection[-1]=='R':\n",
    "       ligne_collection[-1]=1\n",
    "    else:\n",
    "        ligne_collection[-1]=-1\n",
    "    collection.append(ligne_collection)\n",
    "\n",
    "#Mélanger au préalable la colletion\n",
    "shuffle(collection)\n",
    "\n",
    "collection=np.array(collection)\n",
    "X=collection[:,:-1]\n",
    "Y=collection[:,-1]\n",
    "\n",
    "'''\n",
    "On va diviser la collection en un ensemble d'entraînement et un ensemble de test, pour pouvoir évaluer la\n",
    "performance du modèle sur des données qu'il n'a jamais vues pendant l'entraînement(qui n'a pas servi a apprendre le modéle)\n",
    "'''\n",
    "#On divise la collection en 2 parties:une pour l'entrainement(75%) et une pour le test(25%)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'><b>Question 6:</b></font> Appliquer ces modèles sur cette base en prenant comme $MaxEp=500$, le pas d'apprentissage $\\eta=0.1$ et en choisissant les bases Train et Test de façon aléatoire; Reporter l'erreur moyenne de ces modèles obtenues sur les 20 bases Test? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13910/1455021576.py:32: RuntimeWarning: overflow encountered in exp\n",
      "  L=(1-(1/(1+np.exp(-y*self.h(x)))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erreur moyenne du modèle Perceptron: 0.004807692307692308\n",
      "Erreur moyenne du modèle Adaline: 0.0057692307692307696\n",
      "Erreur moyenne du modèle Regression Logistique: 0.006730769230769232\n",
      "Erreur moyenne du modèle SVM: 0.004807692307692308\n"
     ]
    }
   ],
   "source": [
    "\n",
    "erreur_p =[]\n",
    "erreur_a =[]\n",
    "erreur_r =[]\n",
    "erreur_s =[]\n",
    "nb_base_tests=20\n",
    "\n",
    "#A chaque itéaration,on aura des bases d'entrainement et de test différentes\n",
    "for i in range(nb_base_tests):\n",
    "    #Générer une base d'entrainement et une base de test de façon aléatoire grace a train_test_split\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.25)\n",
    "\n",
    "    Test= np.column_stack((X_test, Y_test))\n",
    "    Train= np.column_stack((X_train, Y_train))\n",
    "\n",
    "    w_p=np.zeros(Train.shape[1])\n",
    "    w_a=np.zeros(Train.shape[1])\n",
    "    w_r=np.zeros(Train.shape[1])\n",
    "    w_s=np.zeros(Train.shape[1])\n",
    "\n",
    "    #On initialise les modeles\n",
    "    perceptron = Perceptron(len(Train[0]), eta)\n",
    "    adaline =Adaline(len(Train[0]), eta)\n",
    "    regression_logistique = LogisticRegression(len(Train[0]), eta)\n",
    "    svm= SVM(len(Train[0]), eta)\n",
    "    \n",
    "    # On entraine les modéles \n",
    "    w_p = perceptron.fit(Train,Train.shape[0],MaxEp)\n",
    "    w_a = adaline.fit(Train,Train.shape[0],MaxEp)\n",
    "    w_r = regression_logistique.fit(Train,Train.shape[0],MaxEp)\n",
    "    w_s = svm.fit(Train,Train.shape[0],MaxEp)\n",
    "\n",
    "    \n",
    "    # Calculer l'erreur moyenne sur les données de test\n",
    "    erreur_p.append(perceptron.TAUX_ERREUR(Test))\n",
    "    erreur_a.append(adaline.TAUX_ERREUR(Test))\n",
    "    erreur_r.append(regression_logistique.TAUX_ERREUR(Test))\n",
    "    erreur_s.append(svm.TAUX_ERREUR(Test))\n",
    "    \n",
    "\n",
    "erreur_moyenne_p =np.mean(erreur_p)\n",
    "erreur_moyenne_a =  np.mean(erreur_a)\n",
    "erreur_moyenne_r = np.mean(erreur_r)\n",
    "erreur_moyenne_s =np.mean(erreur_s)\n",
    "\n",
    "print(\"Erreur moyenne du modèle Perceptron:\", erreur_moyenne_p)\n",
    "print(\"Erreur moyenne du modèle Adaline:\", erreur_moyenne_a)\n",
    "print(\"Erreur moyenne du modèle Regression Logistique:\", erreur_moyenne_r)\n",
    "print(\"Erreur moyenne du modèle SVM:\", erreur_moyenne_s)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  | Collection | Adaline            | Perceptron          | Régression Logistique| SVM                 | \n",
    "  |------------|--------------------|---------------------|----------------------|---------------------|\n",
    "  |   SONAR    |0.006730769230769232|0.0028846153846153848|0.009615384615384614  |0.0028846153846153848|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons étudier l'impact de la nomralisation sur les prédictions. Pour cela nous considérons deux stratégies de normalisation communément utilisées dans la littérature:\n",
    "* Stratégie <i>max</i>: consiste à normaliser chaque caractéristique du vecteur réprésentatif d'une observation par la valeur maximale de cette caractéristiques\n",
    "* Stratégie <i>norme</i>: consiste à normaliser chaque caractéristique du vecteur réprésentatif d'une observation par la norme de ce vecteur.\n",
    "\n",
    "Nous considérons ces trois autres collections de la base UCI:\n",
    "\n",
    "        * https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+%28Diagnostic%29\n",
    "        * https://archive.ics.uci.edu/ml/datasets/spambase\n",
    "        * https://archive.ics.uci.edu/ml/datasets/ionosphere\n",
    "\n",
    "<font color='red'><b>Question 7:</b></font> Ecrire une fonction qui prend en entrée la collection des données et qui retourne la collections normalisée suivant les stratégies <i>max</i> et <i>norme</i>. \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Un vecteur=[....]donc les observations sont les lignes de la collection et les caractéristiques sont les colonnes\n",
    "Donc le max sera le max de la colonne\n",
    "Pour chaque observation,on a plusieurs caractéristiques et la dernière caractéristique est la classe\n",
    "'''\n",
    "'''\n",
    "On évitera d'écrire data.iloc[:,-1]=data.iloc[:,-1].replace({unique_values[0]: 1, unique_values[1]: -1}) ou data.loc[:,data.columns[-1]]=data.loc[:,data.columns[-1]].replace({unique_values[0]: 1, unique_values[1]: -1}) \n",
    "pour ne pas avoir l'avertissement de dépréciation, qui indique que dans une future version de pandas, l'utilisation de la méthode iloc,loc\n",
    "avec une affectation directe ne sera plus recommandée.\n",
    "'''\n",
    "\n",
    "def dataFrame_to_collection(data):\n",
    "    collections = []\n",
    "    \n",
    "    for i in range(data.shape[0]):\n",
    "        unique_values =data.iloc[:,-1].unique()#ici c'est que 2 valeurs unique\n",
    "      \n",
    "        data[data.columns[-1]] = data[data.columns[-1]].replace({unique_values[0]: 1, unique_values[1]: -1})\n",
    "        data = data.apply(pd.to_numeric, errors ='coerce')\n",
    "        ligne_collections=data.iloc[i].tolist()\n",
    "       \n",
    "        collections.append(ligne_collections)\n",
    "\n",
    "    return np.array(collections)\n",
    "\n",
    "data_cancer=pd.read_table('https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/breast-cancer-wisconsin.data', sep=',', header=None)\n",
    "data_spam=pd.read_table('https://archive.ics.uci.edu/ml/machine-learning-databases/spambase/spambase.data', sep=',', header=None)\n",
    "data_ionosphere=pd.read_table('https://archive.ics.uci.edu/ml/machine-learning-databases/ionosphere/ionosphere.data', sep=',', header=None)\n",
    "\n",
    "collection_cancer=dataFrame_to_collection(data_cancer)\n",
    "\n",
    "collection_spam=dataFrame_to_collection(data_spam)\n",
    "\n",
    "collection_ionosphere=dataFrame_to_collection(data_ionosphere)\n",
    "\n",
    "\n",
    "def normalisation(collection):\n",
    "    # Stratégie max\n",
    "    collection_max = collection.copy()\n",
    "    #collection.shape[1]-1 car on ne veut pas normaliser la dernière colonne qui est la classe\n",
    "    for i in range(collection.shape[1]-1):\n",
    "        #Pour chaque colonne,on calcule le max\n",
    "        max= np.max(collection[:,i])\n",
    "        if(max!=0):\n",
    "            collection_max[:,i] = collection_max[:,i] / max\n",
    "    # Stratégie norme\n",
    "    collection_norme = collection.copy()\n",
    "    for i in range(collection.shape[0]):\n",
    "        vecteur=collection[i,:-1]\n",
    "        norm = np.linalg.norm(vecteur)\n",
    "        if(norm!=0):\n",
    "            collection_norme[i,:-1] = collection_norme[i,:-1] / norm\n",
    "    return collection_max, collection_norme\n",
    "\n",
    "collection_cancer_max, collection_cancer_norme = normalisation(collection_cancer)\n",
    "collection_spam_max, collection_spam_norme = normalisation(collection_spam)\n",
    "collection_ionosphere_max, collection_ionosphere_norme = normalisation(collection_ionosphere)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'><b>Question 8:</b></font> Compléter les tableaux comparatifs suivants en repertant les erreurs moyennes sur 20 lancements des modèles de Perceptron, de l'Adaline, de la Régression Logistique et des SVM pour les trois cas:\n",
    "\n",
    " '*' Les vecteurs ne sont pas normalisés\n",
    "     \n",
    "  | Collection | Adaline     | Perceptron  | Régression Logistique | SVM |\n",
    "  |------------|-------------|-------------|-----------------------|-----|\n",
    "  |   BREAST   |             |             |                       |     |\n",
    "  |   IONO     |             |             |                       |     |\n",
    "  |   SONAR    |             |             |                       |     |\n",
    "  |   SPAM     |             |             |                       |     |\n",
    "\n",
    " \n",
    " $^n$ Normalisation suivant la stratégie <i>norme</i>\n",
    "     \n",
    "  | Collection | Adaline     | Perceptron  | Régression Logistique | SVM |\n",
    "  |------------|-------------|-------------|-----------------------|-----|\n",
    "  |   BREAST   |             |             |                       |     |\n",
    "  |   IONO     |             |             |                       |     |\n",
    "  |   SONAR    |             |             |                       |     |\n",
    "  |   SPAM     |             |             |                       |     |\n",
    "\n",
    "  \n",
    " $^m$ Normalisation suivant la stratégie <i>max</i>\n",
    "    \n",
    "  | Collection | Adaline     | Perceptron  | Régression Logistique | SVM |\n",
    "  |------------|-------------|-------------|-----------------------|-----|\n",
    "  |   BREAST   |             |             |                       |     |\n",
    "  |   IONO     |             |             |                       |     |\n",
    "  |   SONAR    |             |             |                       |     |\n",
    "  |   SPAM     |             |             |                       |     |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13910/1455021576.py:32: RuntimeWarning: overflow encountered in exp\n",
      "  L=(1-(1/(1+np.exp(-y*self.h(x)))))\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "shapes (10,) and (60,) not aligned: 10 (dim 0) != 60 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[109], line 42\u001b[0m\n\u001b[1;32m     38\u001b[0m     w_p, w_a, w_r, w_s \u001b[39m=\u001b[39m train_models(collection_cancer_max)\n\u001b[1;32m     41\u001b[0m \u001b[39m# Calculer l'erreur moyenne sur les données de test\u001b[39;00m\n\u001b[0;32m---> 42\u001b[0m erreur_p\u001b[39m.\u001b[39mappend(perceptron\u001b[39m.\u001b[39;49mTAUX_ERREUR(Test))\n\u001b[1;32m     43\u001b[0m erreur_a\u001b[39m.\u001b[39mappend(adaline\u001b[39m.\u001b[39mTAUX_ERREUR(Test))\n\u001b[1;32m     44\u001b[0m erreur_r\u001b[39m.\u001b[39mappend(regression_logistique\u001b[39m.\u001b[39mTAUX_ERREUR(Test))\n",
      "Cell \u001b[0;32mIn[103], line 45\u001b[0m, in \u001b[0;36mLinearModel.TAUX_ERREUR\u001b[0;34m(self, Test)\u001b[0m\n\u001b[1;32m     43\u001b[0m Y_test\u001b[39m=\u001b[39mTest[:,\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[1;32m     44\u001b[0m \u001b[39mfor\u001b[39;00m x, y \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(X_test, Y_test):\n\u001b[0;32m---> 45\u001b[0m         nb_mal_classes \u001b[39m=\u001b[39m((\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mh(x)\u001b[39m*\u001b[39my)\u001b[39m<\u001b[39m\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\u001b[39m.\u001b[39msum()\n\u001b[1;32m     46\u001b[0m \u001b[39mreturn\u001b[39;00m nb_mal_classes \u001b[39m/\u001b[39m \u001b[39mlen\u001b[39m(X_test)\n",
      "Cell \u001b[0;32mIn[103], line 18\u001b[0m, in \u001b[0;36mLinearModel.h\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mh\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m     16\u001b[0m     \u001b[39m# Je veux avoir tous w sauf la 1er case(w est un array numpy et non une liste)\u001b[39;00m\n\u001b[1;32m     17\u001b[0m     \u001b[39m# v2:w[0]+sum(Xj*Wj for (Xj,Wj) in zip(x,w[1:]))\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mw[\u001b[39m0\u001b[39m] \u001b[39m+\u001b[39m np\u001b[39m.\u001b[39;49mdot(x, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mw[\u001b[39m1\u001b[39;49m:])\n",
      "File \u001b[0;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (10,) and (60,) not aligned: 10 (dim 0) != 60 (dim 0)"
     ]
    }
   ],
   "source": [
    "\n",
    "def train_models(collection):\n",
    "    perceptron = Perceptron(len(collection[0]), eta)\n",
    "    adaline = Adaline(len(collection[0]), eta)\n",
    "    regression_logistique = LogisticRegression(len(collection[0]), eta)\n",
    "    svm= SVM(len(collection[0]), eta)\n",
    "    return perceptron.fit(collection_cancer,collection_cancer.shape[0],MaxEp), adaline.fit(collection_cancer,collection_cancer.shape[0],MaxEp),regression_logistique.fit(collection_cancer,collection_cancer.shape[0],MaxEp), svm.fit(collection_cancer,collection_cancer.shape[0],MaxEp)\n",
    "\n",
    "for j in range(3):\n",
    "    \n",
    "    XX = collection_cancer[:,:-1]\n",
    "    YY = collection_cancer[:,-1]\n",
    "    erreur_p =[]\n",
    "    erreur_a =[]\n",
    "    erreur_r =[]\n",
    "    erreur_s =[]\n",
    "    nb_base_tests=20\n",
    "    table = [[],[],[],[]]\n",
    "\n",
    "    #A chaque itéaration,on aura des bases d'entrainement et de test différentes\n",
    "    for i in range(nb_base_tests):\n",
    "        #Générer une base d'entrainement et une base de test de façon aléatoire grace a train_test_split\n",
    "        X_train, X_test, Y_train, Y_test = train_test_split(XX, YY, test_size=0.25)\n",
    "        \n",
    "        Test= np.column_stack((X_test, Y_test))\n",
    "        Train= np.column_stack((X_train, Y_train))\n",
    "\n",
    "        w_p=np.zeros(collection_cancer.shape[1])\n",
    "        w_a=np.zeros(collection_cancer.shape[1])\n",
    "        w_r=np.zeros(collection_cancer.shape[1])\n",
    "        w_s=np.zeros(collection_cancer.shape[1])\n",
    "\n",
    "       \n",
    "        if(j==0):\n",
    "            w_p, w_a, w_r, w_s = train_models(collection_cancer)    \n",
    "        elif(j==1):\n",
    "            w_p, w_a, w_r, w_s = train_models(collection_cancer_norme)\n",
    "        elif (j==2):\n",
    "            w_p, w_a, w_r, w_s = train_models(collection_cancer_max)\n",
    "        \n",
    "        \n",
    "        # Calculer l'erreur moyenne sur les données de test\n",
    "        erreur_p.append(perceptron.TAUX_ERREUR(Test))\n",
    "        erreur_a.append(adaline.TAUX_ERREUR(Test))\n",
    "        erreur_r.append(regression_logistique.TAUX_ERREUR(Test))\n",
    "        erreur_s.append(svm.TAUX_ERREUR(Test))\n",
    "    if(j==0):   \n",
    "        print(\"Not normalized version \")  \n",
    "    elif(j==1):\n",
    "        print(\"Normalized version \") \n",
    "    elif (j==2):\n",
    "        print(\"Max version \") \n",
    "    print(\"Adaline\", np.mean(erreur_a),\"Perceptron \", np.mean(erreur_p), \"regression logistique\", np.mean(erreur_r), \"SVM\", np.mean(erreur_s))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
